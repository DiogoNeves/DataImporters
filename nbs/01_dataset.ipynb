{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Building\n",
    "\n",
    "> Processes all included sources and compiles them into a single dataset file `data/dataset/dataset.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from DataImporters.sources.core import Source, process\n",
    "from DataImporters.annotation import load_annotations, apply_annotations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class DatasetPaths:\n",
    "    \"\"\"Container for all the useful paths used to compile a `Dataset`.\"\"\"\n",
    "    def __init__(self, data_path: str, dataset_name: str, annotation_path: str = None):\n",
    "        self.data_path = data_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.intermediate_path = os.path.join(data_path, \"intermediate/\")\n",
    "        self.output_path = os.path.join(data_path, self.dataset_name)\n",
    "        self.audio_output_path = os.path.join(self.output_path, \"audio/\")\n",
    "        self.annotation_path = annotation_path\n",
    "        self.metadata_output_path = os.path.join(self.output_path, \"metadata.csv\")\n",
    "    \n",
    "    def annotation(self, annotation_path: str) -> DatasetPaths:\n",
    "        if not os.path.exists(annotation_path):\n",
    "            raise FileNotFoundError(f\"Annotation file {annotation_path} does not exist\")\n",
    "        \n",
    "        self.annotation_path = annotation_path\n",
    "        return self\n",
    "    \n",
    "    def has_annotation(self) -> bool:\n",
    "        return self.annotation_path is not None\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return pprint.pformat(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_path': None,\n",
       " 'audio_output_path': 'data/test/audio/',\n",
       " 'data_path': 'data',\n",
       " 'dataset_name': 'test',\n",
       " 'intermediate_path': 'data/intermediate/',\n",
       " 'metadata_output_path': 'data/test/metadata.csv',\n",
       " 'output_path': 'data/test'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "paths = DatasetPaths(data_path=\"data\", dataset_name=\"test\")\n",
    "assert paths.annotation_path is None\n",
    "assert paths.output_path == \"data/test\"\n",
    "\n",
    "try:\n",
    "    paths = paths.annotation(\"nope.csv\")\n",
    "    raise Exception(\"Should raise FileNotFoundError if annotation file does not exist\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def _sync_audio_files(source_dir: str, target_dir: str):\n",
    "    \"\"\"Synchronises audio files from source_dir to target_dir. Only copying new files.\"\"\"\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            target_file_path = os.path.join(target_dir, filename)\n",
    "            if not os.path.exists(target_file_path):\n",
    "                shutil.copy2(os.path.join(source_dir, filename), target_file_path)\n",
    "\n",
    "def _delete_audio_files(filenames: str, target_dir: str):\n",
    "    \"\"\"Deletes all audio files in target_dir.\"\"\"\n",
    "    for file in filenames:\n",
    "        os.remove(os.path.join(target_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sources: list[Source],\n",
    "        paths: DatasetPaths\n",
    "    ):\n",
    "        self.sources = sources\n",
    "        self.paths = paths\n",
    "\n",
    "    def _prepare_output(self):\n",
    "        if not os.path.exists(self.paths.audio_output_path):\n",
    "            os.makedirs(self.paths.audio_output_path)\n",
    "\n",
    "    def _compile_source(self, source: str):\n",
    "        source_path = os.path.join(self.paths.intermediate_path, source.name)\n",
    "        _sync_audio_files(source_path, self.paths.audio_output_path)\n",
    "        return pd.read_csv(os.path.join(source_path, \"metadata.csv\"))\n",
    "\n",
    "    def _apply_annotations(self, dataset_metadata: pd.DataFrame):\n",
    "        if not self.paths.has_annotation():\n",
    "            return dataset_metadata\n",
    "\n",
    "        annotations = load_annotations(self.paths.annotation_path)\n",
    "        # We could apply all these before copying the files, but that would spread the logic\n",
    "        # across multiple locations and make it harder to understand. I have no performance\n",
    "        # concerns at this point, so I'm leaving it like this.\n",
    "        metadata = apply_annotations(annotations, dataset_metadata)\n",
    "        _delete_audio_files(annotations.deletes[\"filename\"], self.paths.audio_output_path)\n",
    "        return metadata\n",
    "    \n",
    "    def _package_data(self):\n",
    "        # It syncs with existing dataset, only zipping changed files\n",
    "        os.system(\n",
    "            f\"cd {self.paths.data_path} ; zip -qq -FSr {self.paths.dataset_name}.zip {self.paths.dataset_name}/\"\n",
    "        )\n",
    "    \n",
    "    def compile(self) -> pd.DataFrame:\n",
    "        \"\"\"Compiles a dataset and returns the newly created metadata (already saved).\"\"\"\n",
    "        self._prepare_output()\n",
    "\n",
    "        dataset_metadata = pd.DataFrame()\n",
    "        for source in self.sources:\n",
    "            source_metadata = self._compile_source(source)\n",
    "            dataset_metadata = pd.concat([dataset_metadata, source_metadata])\n",
    "        \n",
    "        clean_dataset = dataset_metadata.drop_duplicates(\"filename\")\n",
    "        diff = len(dataset_metadata) - len(clean_dataset)\n",
    "        if diff != 0:\n",
    "            print(f\"Warning: {diff} duplicate rows found. Some rows were dropped (all files copied).\")\n",
    "            dataset_metadata = clean_dataset\n",
    "        \n",
    "        dataset_metadata = self._apply_annotations(dataset_metadata)\n",
    "        dataset_metadata.to_csv(self.paths.metadata_output_path, index=False)\n",
    "\n",
    "        self._package_data()\n",
    "\n",
    "        return dataset_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Dataset.compile\" class=\"doc_header\"><code>Dataset.compile</code><a href=\"__main__.py#L25\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Dataset.compile</code>()\n",
       "\n",
       "Compiles a dataset and returns the newly created metadata (already saved)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "\n",
    "from nbdev.showdoc import show_doc\n",
    "show_doc(Dataset.compile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
