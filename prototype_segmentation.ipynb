{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype a more automatic way to parse titles into labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first figure out the diversity of titles we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_PATH = \"data/original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_files = [file\n",
    "               for root, _, files in os.walk(ORIGINAL_PATH)\n",
    "               for file in files]\n",
    "audio_files = pd.DataFrame(audio_files, columns=[\"filename\"])\n",
    "audio_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JPG', 'jpg', 'pdf', 'txt', 'wav', 'xls'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_extensions = (\".wav\", \".mp3\", \".m4a\", \".flac\")\n",
    "# get all unique file extensions\n",
    "set([file.split(\".\")[-1] for file in audio_files[\"filename\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No crazy extensions, let's continue with `WAV` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1331, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_files = audio_files[audio_files[\"filename\"].str.endswith(audio_extensions)]\n",
    "audio_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files.to_csv(\"data/audio_files.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stringcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"050_Foley_Footsteps_Concrete_Business_Spin_Turn_Scrape_Special_Distance.wav\"\n",
    "filename2 = \"99S LT Impact - Quakerish A.wav\"\n",
    "filename3 = \"FOOTSTEP - Metal Board Run Barefoot Male - 37.wav\"\n",
    "filename4 = \"Footsteps Grass Scuffs.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOTSTEP - Metal Board Run Barefoot Male - 37.wav\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,536.0,168.0\" width=\"536px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"20.8955%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ORGANIZATION</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">FOOTSTEP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.4478%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.47761%\" x=\"20.8955%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">:</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.1343%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"52.2388%\" x=\"25.3731%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ORGANIZATION</text></svg><svg width=\"20%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Metal</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"20%\" x=\"20%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Board</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"14.2857%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Run</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.1429%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"28.5714%\" x=\"54.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Barefoot</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.5714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"17.1429%\" x=\"82.8571%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Male</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.4286%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.4925%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.47761%\" x=\"77.6119%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">:</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.8507%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.97015%\" x=\"82.0896%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">37</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.0746%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.47761%\" x=\"88.0597%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.2985%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.46269%\" x=\"92.5373%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">wav</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.2687%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('S', [Tree('ORGANIZATION', [('FOOTSTEP', 'NNP')]), ('-', ':'), Tree('ORGANIZATION', [('Metal', 'NNP'), ('Board', 'NNP'), ('Run', 'NNP'), ('Barefoot', 'NNP'), ('Male', 'NNP')]), ('-', ':'), ('37', 'CD'), ('.', '.'), ('wav', 'NN')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.wordpunct_tokenize(filename3)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print(filename3)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/diogoneves/Projects/metaphora/DataImporters/prototype_segmentation.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/diogoneves/Projects/metaphora/DataImporters/prototype_segmentation.ipynb#ch0000024?line=0'>1</a>\u001b[0m nltk\u001b[39m.\u001b[39;49mne_chunk(filename2)\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/chunk/__init__.py:184\u001b[0m, in \u001b[0;36mne_chunk\u001b[0;34m(tagged_tokens, binary)\u001b[0m\n\u001b[1;32m    182\u001b[0m     chunker_pickle \u001b[39m=\u001b[39m _MULTICLASS_NE_CHUNKER\n\u001b[1;32m    183\u001b[0m chunker \u001b[39m=\u001b[39m load(chunker_pickle)\n\u001b[0;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m chunker\u001b[39m.\u001b[39;49mparse(tagged_tokens)\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/chunk/named_entity.py:127\u001b[0m, in \u001b[0;36mNEChunkParser.parse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m, tokens):\n\u001b[1;32m    124\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m    Each token should be a pos-tagged word\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     tagged \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tagger\u001b[39m.\u001b[39;49mtag(tokens)\n\u001b[1;32m    128\u001b[0m     tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tagged_to_parse(tagged)\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/tag/sequential.py:61\u001b[0m, in \u001b[0;36mSequentialBackoffTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     59\u001b[0m tags \u001b[39m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tokens)):\n\u001b[0;32m---> 61\u001b[0m     tags\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag_one(tokens, i, tags))\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(tokens, tags))\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/tag/sequential.py:81\u001b[0m, in \u001b[0;36mSequentialBackoffTagger.tag_one\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     79\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m tagger \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taggers:\n\u001b[0;32m---> 81\u001b[0m     tag \u001b[39m=\u001b[39m tagger\u001b[39m.\u001b[39;49mchoose_tag(tokens, index, history)\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m tag \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/tag/sequential.py:647\u001b[0m, in \u001b[0;36mClassifierBasedTagger.choose_tag\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchoose_tag\u001b[39m(\u001b[39mself\u001b[39m, tokens, index, history):\n\u001b[1;32m    646\u001b[0m     \u001b[39m# Use our feature detector to get the featureset.\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     featureset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_detector(tokens, index, history)\n\u001b[1;32m    649\u001b[0m     \u001b[39m# Use the classifier to pick a tag.  If a cutoff probability\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[39m# was specified, then check that the tag's probability is\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39m# higher than that cutoff first; otherwise, return None.\u001b[39;00m\n\u001b[1;32m    652\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cutoff_prob \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/tag/sequential.py:694\u001b[0m, in \u001b[0;36mClassifierBasedTagger.feature_detector\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_detector\u001b[39m(\u001b[39mself\u001b[39m, tokens, index, history):\n\u001b[1;32m    685\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[39m    Return the feature detector that this tagger uses to generate\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[39m    featuresets for its classifier.  The feature detector is a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39m    See ``classifier()``\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_detector(tokens, index, history)\n",
      "File \u001b[0;32m~/Projects/metaphora/DataImporters/.venv/lib/python3.10/site-packages/nltk/chunk/named_entity.py:58\u001b[0m, in \u001b[0;36mNEChunkParserTagger._feature_detector\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_feature_detector\u001b[39m(\u001b[39mself\u001b[39m, tokens, index, history):\n\u001b[1;32m     57\u001b[0m     word \u001b[39m=\u001b[39m tokens[index][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 58\u001b[0m     pos \u001b[39m=\u001b[39m simplify_pos(tokens[index][\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     60\u001b[0m         prevword \u001b[39m=\u001b[39m prevprevword \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "nltk.ne_chunk(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['050',\n",
       " 'foley',\n",
       " 'footsteps',\n",
       " 'concrete',\n",
       " 'business',\n",
       " 'spin',\n",
       " 'turn',\n",
       " 'scrape',\n",
       " 'special',\n",
       " 'distance',\n",
       " 'wav']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.wordpunct_tokenize(stringcase.sentencecase(filename1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package abc to /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /home/diogoneves/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/webtext.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download(\"brown\")\n",
    "download(\"wordnet\")\n",
    "download(\"abc\")\n",
    "download(\"words\")\n",
    "download(\"reuters\")\n",
    "download(\"webtext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet, brown, abc, words, reuters, webtext\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 41634),\n",
       " ('.', 27350),\n",
       " (',', 26160),\n",
       " ('of', 19307),\n",
       " ('to', 18671),\n",
       " ('and', 14895),\n",
       " ('a', 14605),\n",
       " ('in', 13356),\n",
       " (\"'\", 10217),\n",
       " ('is', 8045)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = nltk.FreqDist([w.lower() for w in abc.words()])\n",
    "freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"050_Foley_Footsteps_Concrete_Business_Spin_Turn_Scrape_Special_Distance.wav\"\n",
    "filename2 = \"99S LT Impact - Quakerish A.wav\"\n",
    "filename3 = \"FOOTSTEP - Metal Board Run Barefoot Male - 37.wav\"\n",
    "filename4 = \"Footsteps Grass Scuffs.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(filename: str) -> list[str]:\n",
    "    name = filename.lower().replace(\".wav\", \"\")\n",
    "    name = re.sub(r\"[^a-z\\s]\", \"\", name)\n",
    "    tokens = nltk.wordpunct_tokenize(name)\n",
    "    frequencies = [freqs.get(t) for t in tokens]\n",
    "    return [(t, freq) for t, freq in zip(tokens, frequencies) if freq is not None and freq > 5 and len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grass', 38)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_labels(filename4.replace(\"_\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance  import edit_distance, jaccard_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "footed\n",
      "metal\n",
      "board\n",
      "run\n",
      "bare\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    temp = [(jaccard_distance(set(ngrams(word, 2)),\n",
    "                              set(ngrams(w, 2))),w)\n",
    "            for w in reuters.words() if w[0]==word[0]]\n",
    "    print(sorted(temp, key = lambda val:val[0])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab4dd34b93fd576d528f2f9c5794caf55e321a8f35f080bc46bcf92cf2ae741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
