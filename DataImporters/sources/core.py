# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_sources_core.ipynb (unless otherwise specified).

__all__ = ['AUDIO_EXTENSIONS', 'Source', 'normalise_label', 'get_footstep_type', 'get_filenames', 'get_hash', 'process']

# Cell

from ..core import load_version

import pandas as pd
import os
import xxhash
import shutil
import stringcase

# These are based on what I find in the data
AUDIO_EXTENSIONS = [".wav"]

# Cell

class Source:
    """All sources should implement this class."""
    def __init__(self, data_path):
        self.data_path = data_path

    @property
    def name(self) -> str:
        raise NotImplementedError()

    def get_files(self, root_path: str) -> list[tuple[str, str]]:
        """List of paths and files to process, as returned by `get_filenames`."""
        raise NotImplementedError()

    def get_category(self, path: str, filename: str) -> str:
        """Category name for the given file (most sources hardcode a single category)."""
        raise NotImplementedError()

    def get_labels(self, path: str, filename: str) -> list[str]:
        """List of labels for the given file."""
        raise NotImplementedError()

    def get_extra(self, path: str, filename: str) -> str:
        """Extra information for the given file."""
        raise NotImplementedError()

# Cell

def normalise_label(label: str) -> str:
    """Normalise a label to be used in the metadata
    (`process` should call this automatically)."""
    return stringcase.capitalcase(stringcase.snakecase(label.lower().strip()))

# Cell

def get_footstep_type(filename: str) -> str:
    step_types = ("walk", "scuffs", "stomps", "squishes", "wade", "scrape")
    for step in step_types:
        if step in filename.lower():
            return step
    return None

# Cell

def get_filenames(root_path: str) -> list[tuple[str, str]]:
    "List audio filenames in the directory."
    return [(root, filename) for root, _, files in os.walk(root_path)
            for filename in files
            if filename.endswith(AUDIO_EXTENSIONS)]

# Cell

def get_hash(file_path: str) -> str:
    "Get the xxhash64 hash of the file."
    with open(os.path.normpath(file_path), "rb") as f:
        return xxhash.xxh64(f.read()).hexdigest()

# Internal Cell

def _prepare_target_dir(target_dir: str):
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

# Internal Cell

def sync_hashed_audio_files(files: tuple[str, str], hashes: list[str], target_dir: str):
    for [path, filename], hash in zip(files, hashes):
        original_file_path = os.path.join(path, filename)
        target_file_path = os.path.join(target_file_path, hash)
        if not os.path.exists(target_file_path):
            shutil.copy2(original_file_path, target_file_path)

# Cell

def process(source: Source) -> pd.DataFrame:
    """Process source and return the metadata."""
    assert source.name is not None and source.name.strip() != ""

    files = source.get_files(source.data_path)
    if len(files) == 0:
        raise ValueError("No files found in source")

    metadata = pd.DataFrame()
    metadata["filename"] = hashed_filenames = [get_hash(os.path.join(path, filename))
                                               for path, filename in files]
    metadata["category"] = [source.get_category(path, filename) for path, filename in files]
    metadata["label"] = [source.get_labels(path, filename) for path, filename in files]
    metadata["extra"] = [source.get_extra(path, filename) for path, filename in files]
    metadata["source"] = [source.name] * len(files)
    metadata["version"] = [load_version()] * len(files)

    target_dir = os.path.join(source.data_path, "intermediate", source.name)
    _prepare_target_dir(target_dir)

    metadata.to_csv(os.path.join(target_dir, "metadata.csv"))
    sync_hashed_audio_files(files, hashed_filenames, target_dir)

    return metadata