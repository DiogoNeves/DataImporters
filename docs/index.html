---

title: Audio Data Importers


keywords: fastai
sidebar: home_sidebar

summary: "A collection of data importers for various audio sources. A loose manual data pipeline."
description: "A collection of data importers for various audio sources. A loose manual data pipeline."
nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pip install dataimporters</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Downloading-Audio-Sources">Downloading Audio Sources<a class="anchor-link" href="#Downloading-Audio-Sources"> </a></h3><p>The audio sources have to be provided manually (for now).<br>
The scripts expect a data directory containing the audio folders:</p>

<pre><code>root
 |- data
      |- original (where you have to place the soundbanks)
      |- intermediate (generated)
      |- dataset (generated)</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset-structure">Dataset structure<a class="anchor-link" href="#Dataset-structure"> </a></h2><p>See <a href="data/dataset/README.md">Dataset README</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipeline">Pipeline<a class="anchor-link" href="#Pipeline"> </a></h2>
<pre><code>mermaid
flowchart TD
    sa[(Source A)] --&gt; pa([Normalise data and create CSV]);
    pa --&gt; ia[(Intermediate A)];
    sb[(Source B)] --&gt; pb([Normalise data and create CSV]);
    pb --&gt; ib[(Intermediate B)];
    ia &amp; ib &amp; a(WIP: Manual annotations by hash) --&gt; c([Compile])
    c-- Some rows can be rejected at this stage --&gt; d[(Dataset)];</code></pre>
<p>Each loader outputs:</p>
<ul>
<li>a CSV, which is then compiled into a single metadata.csv  </li>
<li>the files into an intermediate folder  </li>
</ul>
<p>The process above is done so that:</p>
<ul>
<li>Each notebook is independent  </li>
<li>We can easily compile a final dataset with different sources  </li>
<li>Easier to make the split consistent across runs  </li>
</ul>

</div>
</div>
</div>
</div>


