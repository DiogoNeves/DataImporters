---

title: Audio Data Importers


keywords: fastai
sidebar: home_sidebar

summary: "A collection of data importers for various audio sources. A loose manual data pipeline."
description: "A collection of data importers for various audio sources. A loose manual data pipeline."
nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pip install dataimporters</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Downloading-Audio-Sources">Downloading Audio Sources<a class="anchor-link" href="#Downloading-Audio-Sources"> </a></h3><p>The audio sources have to be provided manually (for now).<br>
The scripts expect a data directory containing the audio folders:</p>

<pre><code>root
 |- data
      |- original (where you have to place the soundbanks)
      |- intermediate (generated)
      |- dataset (generated)</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To create a new dataset package, we simply:</p>
<ol>
<li>import the <a href="/DataImporters/dataset.html#Dataset"><code>Dataset</code></a>,  </li>
<li>give it the sources we'd like to include and the path to our data,  </li>
<li>call <a href="/DataImporters/dataset.html#Dataset.compile"><code>Dataset.compile</code></a></li>
</ol>
<p>The library is flexible, but here's the simplest and most common action we perform:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">DataImporters.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="s2">&quot;data/&quot;</span>
<span class="n">SOURCES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;space_divers_mini&quot;</span><span class="p">,</span>
    <span class="s2">&quot;footsteps_one_ppsfx_004&quot;</span><span class="p">,</span>
    <span class="s2">&quot;footsteps_two_ppsfx_008&quot;</span><span class="p">,</span>
    <span class="s2">&quot;edward_v1.1&quot;</span>
<span class="p">]</span>

<span class="n">metadata</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">SOURCES</span><span class="p">,</span> <span class="n">DATA_PATH</span><span class="p">)</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/DataImporters/dataset.html#Dataset.compile"><code>Dataset.compile</code></a> will return the newly created metadata _(which has already been saved to <code>DATA_PATH</code>)_.</p>
<p>We can use it to confirm we did indeed copy all files. Since the metadata aggregates all the source metadata, if a file is missing, it will still be in the metadata.<br>
On the other hand, this will also let us know when a file has been deleted from the source, but still exists in the dataset folder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s2">&quot;dataset/audio/&quot;</span><span class="p">)))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the assertion fails, this could be due to:</p>
<ul>
<li>Genuine failure to copy  </li>
<li>Some files in the target folder need deleting  <ul>
<li>Please delete them, no code yet</li>
</ul>
</li>
<li>Hash conflict (same content from different sources)  <ul>
<li>In this case, we must debug the sources and make sure there are no duplicates</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset-structure">Dataset structure<a class="anchor-link" href="#Dataset-structure"> </a></h2><p>See <a href="data/dataset/README.md">Dataset README</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipeline">Pipeline<a class="anchor-link" href="#Pipeline"> </a></h2>
<pre><code>mermaid
flowchart TD
    sa[(Source A)] --&gt; pa([Normalise data and create CSV]);
    pa --&gt; ia[(Intermediate A)];
    sb[(Source B)] --&gt; pb([Normalise data and create CSV]);
    pb --&gt; ib[(Intermediate B)];
    ia &amp; ib &amp; a(WIP: Manual annotations by hash) --&gt; c([Compile])
    c-- Some rows can be rejected at this stage --&gt; d[(Dataset)];</code></pre>
<p>Each loader outputs:</p>
<ul>
<li>a CSV, which is then compiled into a single metadata.csv  </li>
<li>the files into an intermediate folder  </li>
</ul>
<p>The process above is done so that:</p>
<ul>
<li>Each notebook is independent  </li>
<li>We can easily compile a final dataset with different sources  </li>
<li>Easier to make the split consistent across runs  </li>
</ul>

</div>
</div>
</div>
</div>


