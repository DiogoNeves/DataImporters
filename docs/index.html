---

title: Audio Data Importers


keywords: fastai
sidebar: home_sidebar

summary: "A collection of data importers for various audio sources. A loose manual data pipeline."
description: "A collection of data importers for various audio sources. A loose manual data pipeline."
nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span>pip install dataimporters
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Downloading-Audio-Sources">Downloading Audio Sources<a class="anchor-link" href="#Downloading-Audio-Sources"> </a></h3><p>The audio sources have to be provided manually (for now).<br>
The scripts expect a data directory containing the audio folders:</p>

<pre><code>root
 |- data/
      |- original/ (where you have to place the soundbanks)
      |- intermediate/ (generated)
      |- dataset/ (generated)</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To create a new dataset package, we simply:</p>
<ol>
<li>Define and process all sources,</li>
<li>import the <a href="/DataImporters/dataset.html#Dataset"><code>Dataset</code></a>,  </li>
<li>give it the sources we'd like to include and the path to our data,  </li>
<li>call <a href="/DataImporters/dataset.html#Dataset.compile"><code>Dataset.compile</code></a></li>
</ol>
<p>This will process all sources and build a final <code>dataset.zip</code> file.</p>
<p>The library is flexible, but here's the simplest and most common action we perform:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">DataImporters.core</span> <span class="kn">import</span> <span class="n">load_version</span>

<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="s2">&quot;data/&quot;</span>
<span class="n">VERSION</span> <span class="o">=</span> <span class="n">load_version</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">DataImporters.sources.core</span> <span class="kn">import</span> <span class="n">process</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.space_divers_mini</span> <span class="kn">import</span> <span class="n">SpaceDiversMini</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.footsteps_one_ppsfx</span> <span class="kn">import</span> <span class="n">FootstepsOnePpsfx</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.footsteps_two_ppsfx</span> <span class="kn">import</span> <span class="n">FootstepsTwoPpsfx</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.edward</span> <span class="kn">import</span> <span class="n">Edward</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.barefoot_metal_sonniss</span> <span class="kn">import</span> <span class="n">BarefootMetalSonniss</span>
<span class="kn">from</span> <span class="nn">DataImporters.sources.custom_fsd</span> <span class="kn">import</span> <span class="n">CustomFsd</span>
<span class="kn">from</span> <span class="nn">DataImporters.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">SpaceDiversMini</span><span class="p">(),</span>
    <span class="n">FootstepsOnePpsfx</span><span class="p">(),</span>
    <span class="n">FootstepsTwoPpsfx</span><span class="p">(),</span>
    <span class="n">Edward</span><span class="p">(),</span>
    <span class="n">BarefootMetalSonniss</span><span class="p">(),</span>
    <span class="n">CustomFsd</span><span class="p">()</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">sources</span><span class="p">:</span>
    <span class="n">process</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">DATA_PATH</span><span class="p">,</span> <span class="n">VERSION</span><span class="p">)</span>

<span class="n">metadata</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">DATA_PATH</span><span class="p">)</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
<span class="n">metadata</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1502</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/DataImporters/dataset.html#Dataset.compile"><code>Dataset.compile</code></a> will return the newly created metadata _(which has already been saved to <code>DATA_PATH</code>)_.</p>
<p>We can use it to confirm we did indeed copy all files. Since the metadata aggregates all the source metadata, if a file is missing, it will still be in the metadata.<br>
On the other hand, this will also let us know when a file has been deleted from the source, but still exists in the dataset folder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s2">&quot;dataset/audio/&quot;</span><span class="p">)))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Everything is looking good, we should bump the <code>version</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">DataImporters.core</span> <span class="kn">import</span> <span class="n">bump_version</span>
<span class="n">bump_version</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the assertion fails, this could be due to:</p>
<ul>
<li>Genuine failure to copy  </li>
<li>Some files in the target folder need deleting  <ul>
<li>Please delete them, no code yet</li>
</ul>
</li>
<li>Hash conflict (same content from different sources)  <ul>
<li>In this case, we must debug the sources and make sure there are no duplicates</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset-Structure">Dataset Structure<a class="anchor-link" href="#Dataset-Structure"> </a></h2>
<pre><code>dataset/
  |- README.md
  |- metadata.csv
  |- audio/
       |- Long list of audio files, filenames are the xxhash64 of the content.</code></pre>
<h3 id="Metadata">Metadata<a class="anchor-link" href="#Metadata"> </a></h3><p><code>metadata.csv</code> contains a list of all the files in the dataset and their labels.</p>
<table>
<thead><tr>
<th>filename</th>
<th>category</th>
<th>label</th>
<th>extra</th>
<th>source</th>
<th>version </th>
</tr>
</thead>
<tbody>
<tr>
<td>File name, assumes all files inside audio folder</td>
<td>Single major category name</td>
<td>Escaped (“”) comma separated list of labels, in snake_case</td>
<td>Extra text/details available for this row (unstructured)</td>
<td>Name of original sound library, snake_case</td>
<td>Version of the last change. Limited to last change only  </td>
</tr>
</tbody>
</table>
<p><em><code>version</code> is a simple incremental integer. If you need to check if a file changed/added simply check if the row <code>version</code> is higher than the last <code>version</code> you ran. Deletes are not supported yet.</em></p>
<p>Here's an example from the sample code ran earlier:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>category</th>
      <th>label</th>
      <th>extra</th>
      <th>source</th>
      <th>version</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>beda557bed5629a2.wav</td>
      <td>Sci_fi</td>
      <td>Manipulate,Distant</td>
      <td>NaN</td>
      <td>space_divers_mini</td>
      <td>14</td>
    </tr>
    <tr>
      <th>1</th>
      <td>56b3dae6f6efd75f.wav</td>
      <td>Sci_fi</td>
      <td>Impact,Crash_distant</td>
      <td>NaN</td>
      <td>space_divers_mini</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pipeline">Pipeline<a class="anchor-link" href="#Pipeline"> </a></h2>
<pre><code>mermaid
flowchart TD
    sa[(Source A)] --&gt; pa([Normalise data and create CSV]);
    pa --&gt; ia[(Intermediate A)];
    sb[(Source B)] --&gt; pb([Normalise data and create CSV]);
    pb --&gt; ib[(Intermediate B)];
    ia &amp; ib &amp; a(WIP: Manual annotations by hash) --&gt; c([Compile])
    c-- Some rows can be rejected at this stage --&gt; d[(Dataset)];</code></pre>
<p>Each loader outputs:</p>
<ul>
<li>a CSV, which is then compiled into a single metadata.csv  </li>
<li>the files into an intermediate folder  </li>
</ul>
<p>The process above is done so that:</p>
<ul>
<li>Each source is independent  </li>
<li>We can easily compile a final dataset with different sources  </li>
<li>Easier to make the split consistent across runs  </li>
</ul>

</div>
</div>
</div>
</div>


